{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Spark Note Reference Spark Overview","title":"Home"},{"location":"#spark-note","text":"","title":"Spark Note"},{"location":"#reference","text":"Spark Overview","title":"Reference"},{"location":"by/","text":"By CREATE TABLE PARTITIONED BY [ PARTITIONED BY ( col3 data_type [ COMMENT col_comment ], ...)] CLUSTERED/SORTED BY [ CLUSTERED BY ( col1 , ...) [ SORTED BY ( col1 [ ASC | DESC ], ...)] INTO num_buckets BUCKETS ] Query ORDER BY CLUSTER BY DISTRIBUTE BY(repartition) # The default number of partitions to use when shuffling data for joins or aggregations. spark.sql.shuffle.partitions = 200 SORT BY WINDOW PARTITION|DISTRIBUTE BY ORDER|SORT BY Writer partitionBy bucketBy sortBy SKEWED BY [ SKEWED BY ( col1 , col2 , ...) ON (( col_value , col_value , ...), ...) Reference","title":"By"},{"location":"by/#by","text":"","title":"By"},{"location":"by/#create-table","text":"","title":"CREATE TABLE"},{"location":"by/#partitioned-by","text":"[ PARTITIONED BY ( col3 data_type [ COMMENT col_comment ], ...)]","title":"PARTITIONED BY"},{"location":"by/#clusteredsorted-by","text":"[ CLUSTERED BY ( col1 , ...) [ SORTED BY ( col1 [ ASC | DESC ], ...)] INTO num_buckets BUCKETS ]","title":"CLUSTERED/SORTED BY"},{"location":"by/#query","text":"","title":"Query"},{"location":"by/#order-by","text":"","title":"ORDER BY"},{"location":"by/#cluster-by","text":"","title":"CLUSTER BY"},{"location":"by/#distribute-byrepartition","text":"# The default number of partitions to use when shuffling data for joins or aggregations. spark.sql.shuffle.partitions = 200","title":"DISTRIBUTE BY(repartition)"},{"location":"by/#sort-by","text":"","title":"SORT BY"},{"location":"by/#window","text":"PARTITION|DISTRIBUTE BY ORDER|SORT BY","title":"WINDOW"},{"location":"by/#writer","text":"","title":"Writer"},{"location":"by/#partitionby","text":"","title":"partitionBy"},{"location":"by/#bucketby","text":"","title":"bucketBy"},{"location":"by/#sortby","text":"","title":"sortBy"},{"location":"by/#skewed-by","text":"[ SKEWED BY ( col1 , col2 , ...) ON (( col_value , col_value , ...), ...)","title":"SKEWED BY"},{"location":"by/#reference","text":"","title":"Reference"},{"location":"graphx/","text":"GraphX Graph Vertex[VertexRDD]\u3001Edge[EdgeRDD]\u3001Triplet[EdgeTriplet]\u3001RoutingTable PartitionStrategy RandomVertexCut CanonicalRandomVertexCut EdgePartition1D EdgePartition2D Construct apply fromEdges fromEdgeTuples Functionality /** Summary of the functionality in the property graph */ class Graph [ VD , ED ] { // Information about the Graph =================================================================== val numEdges : Long val numVertices : Long val inDegrees : VertexRDD [ Int ] val outDegrees : VertexRDD [ Int ] val degrees : VertexRDD [ Int ] // Views of the graph as collections ============================================================= val vertices : VertexRDD [ VD ] val edges : EdgeRDD [ ED ] val triplets : RDD [ EdgeTriplet [ VD , ED ]] // Functions for caching graphs ================================================================== def persist ( newLevel : StorageLevel = StorageLevel . MEMORY_ONLY ) : Graph [ VD , ED ] def cache () : Graph [ VD , ED ] def unpersistVertices ( blocking : Boolean = true ) : Graph [ VD , ED ] // Change the partitioning heuristic ============================================================ def partitionBy ( partitionStrategy : PartitionStrategy ) : Graph [ VD , ED ] // Transform vertex and edge attributes ========================================================== def mapVertices [ VD2 ]( map : ( VertexId , VD ) = VD2 ) : Graph [ VD2 , ED ] def mapEdges [ ED2 ]( map : Edge [ ED ] = ED2 ) : Graph [ VD , ED2 ] def mapEdges [ ED2 ]( map : ( PartitionID , Iterator [ Edge [ ED ]]) = Iterator [ ED2 ]) : Graph [ VD , ED2 ] def mapTriplets [ ED2 ]( map : EdgeTriplet [ VD , ED ] = ED2 ) : Graph [ VD , ED2 ] def mapTriplets [ ED2 ]( map : ( PartitionID , Iterator [ EdgeTriplet [ VD , ED ]]) = Iterator [ ED2 ]) : Graph [ VD , ED2 ] // Modify the graph structure ==================================================================== def reverse : Graph [ VD , ED ] def subgraph ( epred : EdgeTriplet [ VD , ED ] = Boolean = ( x = true ), vpred : ( VertexId , VD ) = Boolean = (( v , d ) = true )) : Graph [ VD , ED ] def mask [ VD2 , ED2 ]( other : Graph [ VD2 , ED2 ]) : Graph [ VD , ED ] def groupEdges ( merge : ( ED , ED ) = ED ) : Graph [ VD , ED ] // Join RDDs with the graph ====================================================================== def joinVertices [ U ]( table : RDD [( VertexId , U )])( mapFunc : ( VertexId , VD , U ) = VD ) : Graph [ VD , ED ] def outerJoinVertices [ U , VD2 ]( other : RDD [( VertexId , U )]) ( mapFunc : ( VertexId , VD , Option [ U ]) = VD2 ) : Graph [ VD2 , ED ] // Aggregate information about adjacent triplets ================================================= def collectNeighborIds ( edgeDirection : EdgeDirection ) : VertexRDD [ Array [ VertexId ]] def collectNeighbors ( edgeDirection : EdgeDirection ) : VertexRDD [ Array [( VertexId , VD )]] def aggregateMessages [ Msg: ClassTag ]( sendMsg : EdgeContext [ VD , ED , Msg ] = Unit , mergeMsg : ( Msg , Msg ) = Msg , tripletFields : TripletFields = TripletFields . All ) : VertexRDD [ A ] // Iterative graph-parallel computation ========================================================== def pregel [ A ]( initialMsg : A , maxIterations : Int , activeDirection : EdgeDirection )( vprog : ( VertexId , VD , A ) = VD , sendMsg : EdgeTriplet [ VD , ED ] = Iterator [( VertexId , A )], mergeMsg : ( A , A ) = A ) : Graph [ VD , ED ] // Basic graph algorithms ======================================================================== def pageRank ( tol : Double , resetProb : Double = 0.15 ) : Graph [ Double , Double ] def connectedComponents () : Graph [ VertexId , ED ] def triangleCount () : Graph [ Int , ED ] def stronglyConnectedComponents ( numIter : Int ) : Graph [ VertexId , ED ] } Algorithm Connected Components Label Propagation PageRank Shortest Paths Strongly Connected Components SVD++ Triangle Count Reference GraphX Programming Guide GraphFrames Overview GraphFrames and GraphX Spark GraphX Source Analysis","title":"GraphX"},{"location":"graphx/#graphx","text":"","title":"GraphX"},{"location":"graphx/#graph","text":"Vertex[VertexRDD]\u3001Edge[EdgeRDD]\u3001Triplet[EdgeTriplet]\u3001RoutingTable","title":"Graph"},{"location":"graphx/#partitionstrategy","text":"RandomVertexCut CanonicalRandomVertexCut EdgePartition1D EdgePartition2D","title":"PartitionStrategy"},{"location":"graphx/#construct","text":"apply fromEdges fromEdgeTuples","title":"Construct"},{"location":"graphx/#functionality","text":"/** Summary of the functionality in the property graph */ class Graph [ VD , ED ] { // Information about the Graph =================================================================== val numEdges : Long val numVertices : Long val inDegrees : VertexRDD [ Int ] val outDegrees : VertexRDD [ Int ] val degrees : VertexRDD [ Int ] // Views of the graph as collections ============================================================= val vertices : VertexRDD [ VD ] val edges : EdgeRDD [ ED ] val triplets : RDD [ EdgeTriplet [ VD , ED ]] // Functions for caching graphs ================================================================== def persist ( newLevel : StorageLevel = StorageLevel . MEMORY_ONLY ) : Graph [ VD , ED ] def cache () : Graph [ VD , ED ] def unpersistVertices ( blocking : Boolean = true ) : Graph [ VD , ED ] // Change the partitioning heuristic ============================================================ def partitionBy ( partitionStrategy : PartitionStrategy ) : Graph [ VD , ED ] // Transform vertex and edge attributes ========================================================== def mapVertices [ VD2 ]( map : ( VertexId , VD ) = VD2 ) : Graph [ VD2 , ED ] def mapEdges [ ED2 ]( map : Edge [ ED ] = ED2 ) : Graph [ VD , ED2 ] def mapEdges [ ED2 ]( map : ( PartitionID , Iterator [ Edge [ ED ]]) = Iterator [ ED2 ]) : Graph [ VD , ED2 ] def mapTriplets [ ED2 ]( map : EdgeTriplet [ VD , ED ] = ED2 ) : Graph [ VD , ED2 ] def mapTriplets [ ED2 ]( map : ( PartitionID , Iterator [ EdgeTriplet [ VD , ED ]]) = Iterator [ ED2 ]) : Graph [ VD , ED2 ] // Modify the graph structure ==================================================================== def reverse : Graph [ VD , ED ] def subgraph ( epred : EdgeTriplet [ VD , ED ] = Boolean = ( x = true ), vpred : ( VertexId , VD ) = Boolean = (( v , d ) = true )) : Graph [ VD , ED ] def mask [ VD2 , ED2 ]( other : Graph [ VD2 , ED2 ]) : Graph [ VD , ED ] def groupEdges ( merge : ( ED , ED ) = ED ) : Graph [ VD , ED ] // Join RDDs with the graph ====================================================================== def joinVertices [ U ]( table : RDD [( VertexId , U )])( mapFunc : ( VertexId , VD , U ) = VD ) : Graph [ VD , ED ] def outerJoinVertices [ U , VD2 ]( other : RDD [( VertexId , U )]) ( mapFunc : ( VertexId , VD , Option [ U ]) = VD2 ) : Graph [ VD2 , ED ] // Aggregate information about adjacent triplets ================================================= def collectNeighborIds ( edgeDirection : EdgeDirection ) : VertexRDD [ Array [ VertexId ]] def collectNeighbors ( edgeDirection : EdgeDirection ) : VertexRDD [ Array [( VertexId , VD )]] def aggregateMessages [ Msg: ClassTag ]( sendMsg : EdgeContext [ VD , ED , Msg ] = Unit , mergeMsg : ( Msg , Msg ) = Msg , tripletFields : TripletFields = TripletFields . All ) : VertexRDD [ A ] // Iterative graph-parallel computation ========================================================== def pregel [ A ]( initialMsg : A , maxIterations : Int , activeDirection : EdgeDirection )( vprog : ( VertexId , VD , A ) = VD , sendMsg : EdgeTriplet [ VD , ED ] = Iterator [( VertexId , A )], mergeMsg : ( A , A ) = A ) : Graph [ VD , ED ] // Basic graph algorithms ======================================================================== def pageRank ( tol : Double , resetProb : Double = 0.15 ) : Graph [ Double , Double ] def connectedComponents () : Graph [ VertexId , ED ] def triangleCount () : Graph [ Int , ED ] def stronglyConnectedComponents ( numIter : Int ) : Graph [ VertexId , ED ] }","title":"Functionality"},{"location":"graphx/#algorithm","text":"Connected Components Label Propagation PageRank Shortest Paths Strongly Connected Components SVD++ Triangle Count","title":"Algorithm"},{"location":"graphx/#reference","text":"GraphX Programming Guide GraphFrames Overview GraphFrames and GraphX Spark GraphX Source Analysis","title":"Reference"},{"location":"hint/","text":"Hint hint : /*+ hintStatements+=hintStatement ( , ? hintStatements+=hintStatement)* */ ; hintStatement : hintName=identifier | hintName=identifier ( parameters+=primaryExpression ( , parameters+=primaryExpression)* ) ; HINT SELECT /*+ HINT(t) */ * FROM t BROADCASTJOIN SELECT /*+ BROADCASTJOIN(b) */ * FROM T1 a JOIN T2 b ON a . key = b . key MAPJOIN SELECT /*+ MAPJOIN(b) */ * FROM T1 a JOIN T2 b ON a . key = b . key STREAMTABLE SELECT /*+ STREAMTABLE(b) */ * FROM T1 a JOIN T2 b ON a . key = b . key INDEX SELECT /*+ INDEX(t, ix_job_name) */ * FROM t COALESCE SELECT /*+ COALESCE(200) */ * FROM t REPARTITION SELECT /*+ REPARTITION(200) */ * FROM t Reference","title":"Hint"},{"location":"hint/#hint","text":"hint : /*+ hintStatements+=hintStatement ( , ? hintStatements+=hintStatement)* */ ; hintStatement : hintName=identifier | hintName=identifier ( parameters+=primaryExpression ( , parameters+=primaryExpression)* ) ; HINT SELECT /*+ HINT(t) */ * FROM t BROADCASTJOIN SELECT /*+ BROADCASTJOIN(b) */ * FROM T1 a JOIN T2 b ON a . key = b . key MAPJOIN SELECT /*+ MAPJOIN(b) */ * FROM T1 a JOIN T2 b ON a . key = b . key STREAMTABLE SELECT /*+ STREAMTABLE(b) */ * FROM T1 a JOIN T2 b ON a . key = b . key INDEX SELECT /*+ INDEX(t, ix_job_name) */ * FROM t COALESCE SELECT /*+ COALESCE(200) */ * FROM t REPARTITION SELECT /*+ REPARTITION(200) */ * FROM t","title":"Hint"},{"location":"hint/#reference","text":"","title":"Reference"},{"location":"join/","text":"Join joinRelation : (joinType) JOIN right=relationPrimary joinCriteria? | NATURAL joinType JOIN right=relationPrimary ; joinType : INNER? | CROSS | LEFT OUTER? | LEFT SEMI | RIGHT OUTER? | FULL OUTER? | LEFT? ANTI ; joinCriteria : ON booleanExpression | USING identifierList ; Reference","title":"Join"},{"location":"join/#join","text":"joinRelation : (joinType) JOIN right=relationPrimary joinCriteria? | NATURAL joinType JOIN right=relationPrimary ; joinType : INNER? | CROSS | LEFT OUTER? | LEFT SEMI | RIGHT OUTER? | FULL OUTER? | LEFT? ANTI ; joinCriteria : ON booleanExpression | USING identifierList ;","title":"Join"},{"location":"join/#reference","text":"","title":"Reference"},{"location":"lateralview/","text":"Lateral View lateralView : LATERAL VIEW (OUTER)? qualifiedName ( (expression ( , expression)*)? ) tblName=identifier (AS? colName+=identifier ( , colName+=identifier)*)? ; Reference","title":"Lateral View"},{"location":"lateralview/#lateral-view","text":"lateralView : LATERAL VIEW (OUTER)? qualifiedName ( (expression ( , expression)*)? ) tblName=identifier (AS? colName+=identifier ( , colName+=identifier)*)? ;","title":"Lateral View"},{"location":"lateralview/#reference","text":"","title":"Reference"},{"location":"mllib/","text":"MLlib Reference Machine Learning Library (MLlib) Guide","title":"MLlib"},{"location":"mllib/#mllib","text":"","title":"MLlib"},{"location":"mllib/#reference","text":"Machine Learning Library (MLlib) Guide","title":"Reference"},{"location":"olap/","text":"OLAP aggregation : GROUP BY groupingExpressions+=expression ( , groupingExpressions+=expression)* ( WITH kind=ROLLUP | WITH kind=CUBE | kind=GROUPING SETS ( groupingSet ( , groupingSet)* ) )? | GROUP BY kind=GROUPING SETS ( groupingSet ( , groupingSet)* ) ; groupingSet : ( (expression ( , expression)*)? ) | expression ; Reference","title":"OLAP"},{"location":"olap/#olap","text":"aggregation : GROUP BY groupingExpressions+=expression ( , groupingExpressions+=expression)* ( WITH kind=ROLLUP | WITH kind=CUBE | kind=GROUPING SETS ( groupingSet ( , groupingSet)* ) )? | GROUP BY kind=GROUPING SETS ( groupingSet ( , groupingSet)* ) ; groupingSet : ( (expression ( , expression)*)? ) | expression ;","title":"OLAP"},{"location":"olap/#reference","text":"","title":"Reference"},{"location":"rdd/","text":"RDD Reference RDD Programming Guide","title":"Basis"},{"location":"rdd/#rdd","text":"","title":"RDD"},{"location":"rdd/#reference","text":"RDD Programming Guide","title":"Reference"},{"location":"reshape/","text":"Reshape pivotClause : PIVOT ( aggregates=namedExpressionSeq FOR pivotColumn IN ( pivotValues+=pivotValue ( , pivotValues+=pivotValue)* ) ) ; pivotColumn : identifiers+=identifier | ( identifiers+=identifier ( , identifiers+=identifier)* ) ; pivotValue : expression (AS? identifier)? ; Reference","title":"Reshape"},{"location":"reshape/#reshape","text":"pivotClause : PIVOT ( aggregates=namedExpressionSeq FOR pivotColumn IN ( pivotValues+=pivotValue ( , pivotValues+=pivotValue)* ) ) ; pivotColumn : identifiers+=identifier | ( identifiers+=identifier ( , identifiers+=identifier)* ) ; pivotValue : expression (AS? identifier)? ;","title":"Reshape"},{"location":"reshape/#reference","text":"","title":"Reference"},{"location":"sql/","text":"SQL Reference Spark SQL, DataFrames and Datasets Guide Spark SQL, Built-in Functions SQL Guide DataFrames and Datasets","title":"SQL"},{"location":"sql/#sql","text":"","title":"SQL"},{"location":"sql/#reference","text":"Spark SQL, DataFrames and Datasets Guide Spark SQL, Built-in Functions SQL Guide DataFrames and Datasets","title":"Reference"},{"location":"statistics/","text":"Statistics Estimates of various statistics. The default estimation logic simply lazily multiplies the corresponding statistic produced by the children. Statistics - CatalogStatistics sizeInBytes: Physical size in bytes. For leaf operators this defaults to 1, otherwise it defaults to the product of children's sizeInBytes rowCount: Estimated number of rows attributeStats: Statistics for Attributes hints: Query hints ColumnStat - CatalogColumnStat distinctCount: number of distinct values min: minimum value max: maximum value nullCount: number of nulls avgLen: average length of the values maxLen: maximum length of the values histogram: histogram of the values Histogram[HistogramBin] height: number of rows in each bin bins: equi-height histogram bins lo: lower bound of the value range in this bin hi: higher bound of the value range in this bin ndv: approximate number of distinct values in this bin HintInfo broadcast join/shuffle DataFrameStatFunctions Statistic functions for DataFrames.(Since: 1.4.0) approxQuantile: Calculates the approximate quantiles of numerical columns of a DataFrame bloomFilter: Builds a Bloom filter over a specified column corr: Calculates the Pearson Correlation Coefficient of two columns of a DataFrame countMinSketch: Builds a Count-min Sketch over a specified column cov: Calculate the sample covariance of two numerical columns of a DataFrame crosstab: Computes a pair-wise frequency table of the given columns freqItems: (Scala-specific) Finding frequent items for columns, possibly with false positives sampleBy: Returns a stratified sample without replacement based on the fraction given on each stratum Other Dataset#describe count, mean, stddev, min, max StatFunctions.summary(ds, Seq(\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\")) Statistics API for statistical functions in MLlib colStats[MultivariateOnlineSummarizer]: column-wise summary statistics corr: Pearson correlation matrix chiSqTest: chi-squared test kolmogorovSmirnovTest: Kolmogorov-Smirnov test Reference Spark SQL Package Summary","title":"Statistics"},{"location":"statistics/#statistics","text":"Estimates of various statistics. The default estimation logic simply lazily multiplies the corresponding statistic produced by the children.","title":"Statistics"},{"location":"statistics/#statistics-catalogstatistics","text":"sizeInBytes: Physical size in bytes. For leaf operators this defaults to 1, otherwise it defaults to the product of children's sizeInBytes rowCount: Estimated number of rows attributeStats: Statistics for Attributes hints: Query hints","title":"Statistics -&gt; CatalogStatistics"},{"location":"statistics/#columnstat-catalogcolumnstat","text":"distinctCount: number of distinct values min: minimum value max: maximum value nullCount: number of nulls avgLen: average length of the values maxLen: maximum length of the values histogram: histogram of the values","title":"ColumnStat -&gt; CatalogColumnStat"},{"location":"statistics/#histogramhistogrambin","text":"height: number of rows in each bin bins: equi-height histogram bins lo: lower bound of the value range in this bin hi: higher bound of the value range in this bin ndv: approximate number of distinct values in this bin","title":"Histogram[HistogramBin]"},{"location":"statistics/#hintinfo","text":"broadcast join/shuffle","title":"HintInfo"},{"location":"statistics/#dataframestatfunctions","text":"Statistic functions for DataFrames.(Since: 1.4.0) approxQuantile: Calculates the approximate quantiles of numerical columns of a DataFrame bloomFilter: Builds a Bloom filter over a specified column corr: Calculates the Pearson Correlation Coefficient of two columns of a DataFrame countMinSketch: Builds a Count-min Sketch over a specified column cov: Calculate the sample covariance of two numerical columns of a DataFrame crosstab: Computes a pair-wise frequency table of the given columns freqItems: (Scala-specific) Finding frequent items for columns, possibly with false positives sampleBy: Returns a stratified sample without replacement based on the fraction given on each stratum","title":"DataFrameStatFunctions"},{"location":"statistics/#other","text":"","title":"Other"},{"location":"statistics/#datasetdescribe","text":"count, mean, stddev, min, max StatFunctions.summary(ds, Seq(\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"))","title":"Dataset#describe"},{"location":"statistics/#statistics_1","text":"API for statistical functions in MLlib colStats[MultivariateOnlineSummarizer]: column-wise summary statistics corr: Pearson correlation matrix chiSqTest: chi-squared test kolmogorovSmirnovTest: Kolmogorov-Smirnov test","title":"Statistics"},{"location":"statistics/#reference","text":"Spark SQL Package Summary","title":"Reference"},{"location":"streaming/","text":"Streaming Reference Structured Streaming Programming Guide Spark Streaming Programming Guide lw-lin/CoolplaySpark","title":"Streaming"},{"location":"streaming/#streaming","text":"","title":"Streaming"},{"location":"streaming/#reference","text":"Structured Streaming Programming Guide Spark Streaming Programming Guide lw-lin/CoolplaySpark","title":"Reference"},{"location":"structured-streaming/","text":"Structured Streaming Reference Structured Streaming Programming Guide Spark Streaming Programming Guide lw-lin/CoolplaySpark","title":"Structured Streaming"},{"location":"structured-streaming/#structured-streaming","text":"","title":"Structured Streaming"},{"location":"structured-streaming/#reference","text":"Structured Streaming Programming Guide Spark Streaming Programming Guide lw-lin/CoolplaySpark","title":"Reference"},{"location":"window/","text":"Window windowSpec : name=identifier #windowRef | ( name=identifier ) #windowRef | ( ( CLUSTER BY partition+=expression ( , partition+=expression)* | ((PARTITION | DISTRIBUTE) BY partition+=expression ( , partition+=expression)*)? ((ORDER | SORT) BY sortItem ( , sortItem)*)?) windowFrame? ) #windowDef ; windowFrame : frameType=RANGE start=frameBound | frameType=ROWS start=frameBound | frameType=RANGE BETWEEN start=frameBound AND end=frameBound | frameType=ROWS BETWEEN start=frameBound AND end=frameBound ; frameBound : UNBOUNDED boundType=(PRECEDING | FOLLOWING) | boundType=CURRENT ROW | expression boundType=(PRECEDING | FOLLOWING) ; Reference","title":"Window"},{"location":"window/#window","text":"windowSpec : name=identifier #windowRef | ( name=identifier ) #windowRef | ( ( CLUSTER BY partition+=expression ( , partition+=expression)* | ((PARTITION | DISTRIBUTE) BY partition+=expression ( , partition+=expression)*)? ((ORDER | SORT) BY sortItem ( , sortItem)*)?) windowFrame? ) #windowDef ; windowFrame : frameType=RANGE start=frameBound | frameType=ROWS start=frameBound | frameType=RANGE BETWEEN start=frameBound AND end=frameBound | frameType=ROWS BETWEEN start=frameBound AND end=frameBound ; frameBound : UNBOUNDED boundType=(PRECEDING | FOLLOWING) | boundType=CURRENT ROW | expression boundType=(PRECEDING | FOLLOWING) ;","title":"Window"},{"location":"window/#reference","text":"","title":"Reference"}]}