{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Spark Note \u00b6 Reference \u00b6 Spark Overview","title":"Home"},{"location":"#spark-note","text":"","title":"Spark Note"},{"location":"#reference","text":"Spark Overview","title":"Reference"},{"location":"graphx/","text":"GraphX \u00b6 Graph \u00b6 Vertex[VertexRDD]\u3001Edge[EdgeRDD]\u3001Triplet[EdgeTriplet]\u3001RoutingTable PartitionStrategy \u00b6 EdgePartition2D EdgePartition1D RandomVertexCut CanonicalRandomVertexCut Construct \u00b6 fromEdgeTuples fromEdges apply Functionality \u00b6 /** Summary of the functionality in the property graph */ class Graph [ VD , ED ] { // Information about the Graph =================================================================== val numEdges : Long val numVertices : Long val inDegrees : VertexRDD [ Int ] val outDegrees : VertexRDD [ Int ] val degrees : VertexRDD [ Int ] // Views of the graph as collections ============================================================= val vertices : VertexRDD [ VD ] val edges : EdgeRDD [ ED ] val triplets : RDD [ EdgeTriplet [ VD , ED ]] // Functions for caching graphs ================================================================== def persist ( newLevel : StorageLevel = StorageLevel . MEMORY_ONLY ) : Graph [ VD , ED ] def cache () : Graph [ VD , ED ] def unpersistVertices ( blocking : Boolean = true ) : Graph [ VD , ED ] // Change the partitioning heuristic ============================================================ def partitionBy ( partitionStrategy : PartitionStrategy ) : Graph [ VD , ED ] // Transform vertex and edge attributes ========================================================== def mapVertices [ VD2 ]( map : ( VertexId , VD ) => VD2 ) : Graph [ VD2 , ED ] def mapEdges [ ED2 ]( map : Edge [ ED ] => ED2 ) : Graph [ VD , ED2 ] def mapEdges [ ED2 ]( map : ( PartitionID , Iterator [ Edge [ ED ]]) => Iterator [ ED2 ]) : Graph [ VD , ED2 ] def mapTriplets [ ED2 ]( map : EdgeTriplet [ VD , ED ] => ED2 ) : Graph [ VD , ED2 ] def mapTriplets [ ED2 ]( map : ( PartitionID , Iterator [ EdgeTriplet [ VD , ED ]]) => Iterator [ ED2 ]) : Graph [ VD , ED2 ] // Modify the graph structure ==================================================================== def reverse : Graph [ VD , ED ] def subgraph ( epred : EdgeTriplet [ VD , ED ] => Boolean = ( x => true ), vpred : ( VertexId , VD ) => Boolean = (( v , d ) => true )) : Graph [ VD , ED ] def mask [ VD2 , ED2 ]( other : Graph [ VD2 , ED2 ]) : Graph [ VD , ED ] def groupEdges ( merge : ( ED , ED ) => ED ) : Graph [ VD , ED ] // Join RDDs with the graph ====================================================================== def joinVertices [ U ]( table : RDD [( VertexId , U )])( mapFunc : ( VertexId , VD , U ) => VD ) : Graph [ VD , ED ] def outerJoinVertices [ U , VD2 ]( other : RDD [( VertexId , U )]) ( mapFunc : ( VertexId , VD , Option [ U ]) => VD2 ) : Graph [ VD2 , ED ] // Aggregate information about adjacent triplets ================================================= def collectNeighborIds ( edgeDirection : EdgeDirection ) : VertexRDD [ Array [ VertexId ]] def collectNeighbors ( edgeDirection : EdgeDirection ) : VertexRDD [ Array [( VertexId , VD )]] def aggregateMessages [ Msg: ClassTag ]( sendMsg : EdgeContext [ VD , ED , Msg ] => Unit , mergeMsg : ( Msg , Msg ) => Msg , tripletFields : TripletFields = TripletFields . All ) : VertexRDD [ A ] // Iterative graph-parallel computation ========================================================== def pregel [ A ]( initialMsg : A , maxIterations : Int , activeDirection : EdgeDirection )( vprog : ( VertexId , VD , A ) => VD , sendMsg : EdgeTriplet [ VD , ED ] => Iterator [( VertexId , A )], mergeMsg : ( A , A ) => A ) : Graph [ VD , ED ] // Basic graph algorithms ======================================================================== def pageRank ( tol : Double , resetProb : Double = 0.15 ) : Graph [ Double , Double ] def connectedComponents () : Graph [ VertexId , ED ] def triangleCount () : Graph [ Int , ED ] def stronglyConnectedComponents ( numIter : Int ) : Graph [ VertexId , ED ] } Algorithm \u00b6 Connected Components Label Propagation PageRank Shortest Paths Strongly Connected Components SVD++ Triangle Count Reference \u00b6 GraphX Programming Guide","title":"GraphX"},{"location":"graphx/#graphx","text":"","title":"GraphX"},{"location":"graphx/#graph","text":"Vertex[VertexRDD]\u3001Edge[EdgeRDD]\u3001Triplet[EdgeTriplet]\u3001RoutingTable","title":"Graph"},{"location":"graphx/#partitionstrategy","text":"EdgePartition2D EdgePartition1D RandomVertexCut CanonicalRandomVertexCut","title":"PartitionStrategy"},{"location":"graphx/#construct","text":"fromEdgeTuples fromEdges apply","title":"Construct"},{"location":"graphx/#functionality","text":"/** Summary of the functionality in the property graph */ class Graph [ VD , ED ] { // Information about the Graph =================================================================== val numEdges : Long val numVertices : Long val inDegrees : VertexRDD [ Int ] val outDegrees : VertexRDD [ Int ] val degrees : VertexRDD [ Int ] // Views of the graph as collections ============================================================= val vertices : VertexRDD [ VD ] val edges : EdgeRDD [ ED ] val triplets : RDD [ EdgeTriplet [ VD , ED ]] // Functions for caching graphs ================================================================== def persist ( newLevel : StorageLevel = StorageLevel . MEMORY_ONLY ) : Graph [ VD , ED ] def cache () : Graph [ VD , ED ] def unpersistVertices ( blocking : Boolean = true ) : Graph [ VD , ED ] // Change the partitioning heuristic ============================================================ def partitionBy ( partitionStrategy : PartitionStrategy ) : Graph [ VD , ED ] // Transform vertex and edge attributes ========================================================== def mapVertices [ VD2 ]( map : ( VertexId , VD ) => VD2 ) : Graph [ VD2 , ED ] def mapEdges [ ED2 ]( map : Edge [ ED ] => ED2 ) : Graph [ VD , ED2 ] def mapEdges [ ED2 ]( map : ( PartitionID , Iterator [ Edge [ ED ]]) => Iterator [ ED2 ]) : Graph [ VD , ED2 ] def mapTriplets [ ED2 ]( map : EdgeTriplet [ VD , ED ] => ED2 ) : Graph [ VD , ED2 ] def mapTriplets [ ED2 ]( map : ( PartitionID , Iterator [ EdgeTriplet [ VD , ED ]]) => Iterator [ ED2 ]) : Graph [ VD , ED2 ] // Modify the graph structure ==================================================================== def reverse : Graph [ VD , ED ] def subgraph ( epred : EdgeTriplet [ VD , ED ] => Boolean = ( x => true ), vpred : ( VertexId , VD ) => Boolean = (( v , d ) => true )) : Graph [ VD , ED ] def mask [ VD2 , ED2 ]( other : Graph [ VD2 , ED2 ]) : Graph [ VD , ED ] def groupEdges ( merge : ( ED , ED ) => ED ) : Graph [ VD , ED ] // Join RDDs with the graph ====================================================================== def joinVertices [ U ]( table : RDD [( VertexId , U )])( mapFunc : ( VertexId , VD , U ) => VD ) : Graph [ VD , ED ] def outerJoinVertices [ U , VD2 ]( other : RDD [( VertexId , U )]) ( mapFunc : ( VertexId , VD , Option [ U ]) => VD2 ) : Graph [ VD2 , ED ] // Aggregate information about adjacent triplets ================================================= def collectNeighborIds ( edgeDirection : EdgeDirection ) : VertexRDD [ Array [ VertexId ]] def collectNeighbors ( edgeDirection : EdgeDirection ) : VertexRDD [ Array [( VertexId , VD )]] def aggregateMessages [ Msg: ClassTag ]( sendMsg : EdgeContext [ VD , ED , Msg ] => Unit , mergeMsg : ( Msg , Msg ) => Msg , tripletFields : TripletFields = TripletFields . All ) : VertexRDD [ A ] // Iterative graph-parallel computation ========================================================== def pregel [ A ]( initialMsg : A , maxIterations : Int , activeDirection : EdgeDirection )( vprog : ( VertexId , VD , A ) => VD , sendMsg : EdgeTriplet [ VD , ED ] => Iterator [( VertexId , A )], mergeMsg : ( A , A ) => A ) : Graph [ VD , ED ] // Basic graph algorithms ======================================================================== def pageRank ( tol : Double , resetProb : Double = 0.15 ) : Graph [ Double , Double ] def connectedComponents () : Graph [ VertexId , ED ] def triangleCount () : Graph [ Int , ED ] def stronglyConnectedComponents ( numIter : Int ) : Graph [ VertexId , ED ] }","title":"Functionality"},{"location":"graphx/#algorithm","text":"Connected Components Label Propagation PageRank Shortest Paths Strongly Connected Components SVD++ Triangle Count","title":"Algorithm"},{"location":"graphx/#reference","text":"GraphX Programming Guide","title":"Reference"},{"location":"mllib/","text":"MLlib \u00b6 Reference \u00b6 - Machine Learning Library (MLlib) Guide","title":"MLlib"},{"location":"mllib/#mllib","text":"","title":"MLlib"},{"location":"mllib/#reference","text":"- Machine Learning Library (MLlib) Guide","title":"Reference"},{"location":"rdd/","text":"RDD \u00b6 Reference \u00b6 - RDD Programming Guide","title":"Basis"},{"location":"rdd/#rdd","text":"","title":"RDD"},{"location":"rdd/#reference","text":"- RDD Programming Guide","title":"Reference"},{"location":"sql/","text":"SQL \u00b6 Reference \u00b6 Spark SQL, DataFrames and Datasets Guide Spark SQL, Built-in Functions","title":"SQL"},{"location":"sql/#sql","text":"","title":"SQL"},{"location":"sql/#reference","text":"Spark SQL, DataFrames and Datasets Guide Spark SQL, Built-in Functions","title":"Reference"},{"location":"statistics/","text":"Statistics \u00b6 Estimates of various statistics. The default estimation logic simply lazily multiplies the corresponding statistic produced by the children. Statistics -> CatalogStatistics \u00b6 sizeInBytes: Physical size in bytes. For leaf operators this defaults to 1, otherwise it defaults to the product of children's sizeInBytes rowCount: Estimated number of rows attributeStats: Statistics for Attributes hints: Query hints ColumnStat -> CatalogColumnStat \u00b6 distinctCount: number of distinct values min: minimum value max: maximum value nullCount: number of nulls avgLen: average length of the values maxLen: maximum length of the values histogram: histogram of the values Histogram[HistogramBin] \u00b6 height: number of rows in each bin bins: equi-height histogram bins lo: lower bound of the value range in this bin hi: higher bound of the value range in this bin ndv: approximate number of distinct values in this bin HintInfo \u00b6 broadcast join/shuffle DataFrameStatFunctions \u00b6 Statistic functions for DataFrames.(Since: 1.4.0) approxQuantile: Calculates the approximate quantiles of numerical columns of a DataFrame bloomFilter: Builds a Bloom filter over a specified column corr: Calculates the Pearson Correlation Coefficient of two columns of a DataFrame countMinSketch: Builds a Count-min Sketch over a specified column cov: Calculate the sample covariance of two numerical columns of a DataFrame crosstab: Computes a pair-wise frequency table of the given columns freqItems: (Scala-specific) Finding frequent items for columns, possibly with false positives sampleBy: Returns a stratified sample without replacement based on the fraction given on each stratum Other \u00b6 Dataset#describe \u00b6 count, mean, stddev, min, max StatFunctions.summary(ds, Seq(\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\")) Statistics \u00b6 API for statistical functions in MLlib colStats[MultivariateOnlineSummarizer]: column-wise summary statistics corr: Pearson correlation matrix chiSqTest: chi-squared test kolmogorovSmirnovTest: Kolmogorov-Smirnov test Reference \u00b6 Spark SQL Package Summary","title":"Statistics"},{"location":"statistics/#statistics","text":"Estimates of various statistics. The default estimation logic simply lazily multiplies the corresponding statistic produced by the children.","title":"Statistics"},{"location":"statistics/#statistics-catalogstatistics","text":"sizeInBytes: Physical size in bytes. For leaf operators this defaults to 1, otherwise it defaults to the product of children's sizeInBytes rowCount: Estimated number of rows attributeStats: Statistics for Attributes hints: Query hints","title":"Statistics -&gt; CatalogStatistics"},{"location":"statistics/#columnstat-catalogcolumnstat","text":"distinctCount: number of distinct values min: minimum value max: maximum value nullCount: number of nulls avgLen: average length of the values maxLen: maximum length of the values histogram: histogram of the values","title":"ColumnStat -&gt; CatalogColumnStat"},{"location":"statistics/#histogramhistogrambin","text":"height: number of rows in each bin bins: equi-height histogram bins lo: lower bound of the value range in this bin hi: higher bound of the value range in this bin ndv: approximate number of distinct values in this bin","title":"Histogram[HistogramBin]"},{"location":"statistics/#hintinfo","text":"broadcast join/shuffle","title":"HintInfo"},{"location":"statistics/#dataframestatfunctions","text":"Statistic functions for DataFrames.(Since: 1.4.0) approxQuantile: Calculates the approximate quantiles of numerical columns of a DataFrame bloomFilter: Builds a Bloom filter over a specified column corr: Calculates the Pearson Correlation Coefficient of two columns of a DataFrame countMinSketch: Builds a Count-min Sketch over a specified column cov: Calculate the sample covariance of two numerical columns of a DataFrame crosstab: Computes a pair-wise frequency table of the given columns freqItems: (Scala-specific) Finding frequent items for columns, possibly with false positives sampleBy: Returns a stratified sample without replacement based on the fraction given on each stratum","title":"DataFrameStatFunctions"},{"location":"statistics/#other","text":"","title":"Other"},{"location":"statistics/#datasetdescribe","text":"count, mean, stddev, min, max StatFunctions.summary(ds, Seq(\"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"))","title":"Dataset#describe"},{"location":"statistics/#statistics_1","text":"API for statistical functions in MLlib colStats[MultivariateOnlineSummarizer]: column-wise summary statistics corr: Pearson correlation matrix chiSqTest: chi-squared test kolmogorovSmirnovTest: Kolmogorov-Smirnov test","title":"Statistics"},{"location":"statistics/#reference","text":"Spark SQL Package Summary","title":"Reference"},{"location":"streaming/","text":"Streaming \u00b6 Reference \u00b6 Structured Streaming Programming Guide Spark Streaming Programming Guide lw-lin/CoolplaySpark","title":"Streaming"},{"location":"streaming/#streaming","text":"","title":"Streaming"},{"location":"streaming/#reference","text":"Structured Streaming Programming Guide Spark Streaming Programming Guide lw-lin/CoolplaySpark","title":"Reference"}]}